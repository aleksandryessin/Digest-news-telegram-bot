# AI News Digest Bot - Project Structure

This document outlines the project structure and organization of the AI News Digest Bot.

## ğŸ“ Directory Structure

```
ai-news-digest-bot/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ __init__.py              # Main package
â”‚   â”œâ”€â”€ main.py                  # Entry point and main orchestrator
â”‚   â”œâ”€â”€ extractors/              # News extraction modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ article_extractor.py # Individual article content extraction
â”‚   â”‚   â””â”€â”€ source_extractor.py  # Multi-source news collection
â”‚   â”œâ”€â”€ services/                # Core business services
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ai_summarizer.py     # OpenAI summarization service
â”‚   â”‚   â”œâ”€â”€ database.py          # SQLite database management
â”‚   â”‚   â””â”€â”€ telegram_bot.py      # Telegram posting service
â”‚   â””â”€â”€ utils/                   # Utility modules
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ extract_links.py     # HTML link extraction
â”‚       â””â”€â”€ logger_config.py     # Logging configuration
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ .env.example            # Environment variables template
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ scripts/                     # Deployment and utility scripts
â”‚   â”œâ”€â”€ deploy.sh               # Docker deployment script
â”‚   â””â”€â”€ docker-compose.yml      # Docker Compose configuration
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ README.md               # Main project documentation
â”‚   â”œâ”€â”€ setup_guide.md          # Setup and installation guide
â”‚   â””â”€â”€ project_structure.md    # This file
â”œâ”€â”€ Dockerfile                   # Docker image configuration
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ .env                        # Environment variables (excluded from git)
â””â”€â”€ data/                       # Persistent data (created by Docker)
    â”œâ”€â”€ news_digest.db          # SQLite database
    â””â”€â”€ logs/                   # Application logs
```

## ğŸ—ï¸ Architecture Overview

### **Core Components**

1. **Main Orchestrator** (`src/main.py`)
   - Entry point for the application
   - Coordinates all services
   - Handles scheduling and command-line interface

2. **Extractors** (`src/extractors/`)
   - **Source Extractor**: Collects articles from 9 news sources
   - **Article Extractor**: Downloads and parses individual article content

3. **Services** (`src/services/`)
   - **AI Summarizer**: Generates Russian summaries using OpenAI
   - **Database**: Manages article storage and deduplication
   - **Telegram Bot**: Formats and posts digests to channels

4. **Utilities** (`src/utils/`)
   - **Link Extractor**: Parses HTML for article URLs
   - **Logger**: Structured logging configuration

### **Data Flow**

```
News Sources â†’ Source Extractor â†’ Article Extractor â†’ AI Summarizer â†’ Database â†’ Telegram Bot â†’ Channel
```

1. **Collection**: Fetch article URLs from news sources
2. **Extraction**: Download full article content
3. **Summarization**: Generate Russian summaries
4. **Storage**: Save to database with deduplication
5. **Publishing**: Format and post to Telegram

## ğŸ”§ Configuration

### **Environment Variables** (`.env`)
- `OPENAI_API_KEY`: OpenAI API key for summarization
- `TELEGRAM_BOT_TOKEN`: Telegram bot authentication
- `TELEGRAM_CHANNEL_ID`: Target channel for posting
- `MAX_ARTICLES_PER_DIGEST`: Articles per digest (default: 15)
- `SUMMARY_MAX_WORDS`: Max words per summary (default: 100)
- `DIGEST_TIME`: Daily posting time (default: 09:00 UTC)

### **Dependencies** (`config/requirements.txt`)
- `beautifulsoup4`: HTML parsing
- `requests`: HTTP requests
- `openai`: AI summarization
- `python-telegram-bot`: Telegram integration
- `schedule`: Task scheduling
- `python-dotenv`: Environment management

## ğŸš€ Deployment

### **Docker Deployment**
```bash
cd scripts/
./deploy.sh start    # Start the bot
./deploy.sh test     # Run test digest
./deploy.sh logs     # View logs
./deploy.sh status   # Check status
```

### **Local Development**
```bash
python src/main.py run-once    # One-time run
python src/main.py collect     # Collect articles only
python src/main.py digest      # Create digest only
python src/main.py schedule    # Start scheduler
```

## ğŸ“Š Database Schema

### **Articles Table**
- `id`: Primary key
- `url`: Article URL (unique)
- `url_hash`: URL hash for deduplication
- `title`: Article title
- `content`: Full article text
- `summary`: Russian summary
- `source`: News source name
- `relevance_score`: AI relevance score
- `created_at`: Creation timestamp

### **Digest Posts Table**
- `id`: Primary key
- `date`: Digest date
- `article_ids`: JSON array of posted articles
- `telegram_message_id`: Telegram message ID
- `created_at`: Creation timestamp

### **Source Stats Table**
- `source`: News source name
- `date`: Processing date
- `articles_found`: Articles discovered
- `articles_processed`: Articles successfully processed

## ğŸ” News Sources

The bot collects from these sources:
- **TechCrunch**: `https://techcrunch.com/tag/ai/`
- **Wired**: `https://www.wired.com/tag/artificial-intelligence/`
- **The Verge**: `https://www.theverge.com/ai-artificial-intelligence`
- **VentureBeat**: `https://venturebeat.com/ai/`
- **MIT Tech Review**: `https://www.technologyreview.com/topic/artificial-intelligence/`
- **Ars Technica**: `https://arstechnica.com/information-technology/artificial-intelligence/`
- **ZDNet**: `https://www.zdnet.com/topic/artificial-intelligence/`
- **Forbes**: `https://www.forbes.com/ai/`
- **Bloomberg**: `https://www.bloomberg.com/topics/artificial-intelligence`

## ğŸ“ˆ Monitoring

### **Logs**
- Console output with timestamps
- File logging to `/app/logs/bot.log`
- Structured logging with log levels

### **Statistics**
- Articles processed per source
- Success/failure rates
- Average relevance scores
- Database growth metrics

## ğŸ› ï¸ Development

### **Adding New Sources**
1. Add URL and extraction logic to `src/extractors/source_extractor.py`
2. Add source-specific parsing to `src/extractors/article_extractor.py`
3. Update relevance scoring if needed

### **Modifying Summarization**
1. Edit prompts in `src/services/ai_summarizer.py`
2. Adjust OpenAI model parameters
3. Test with different content types

### **Changing Telegram Format**
1. Modify message templates in `src/services/telegram_bot.py`
2. Adjust character limits and formatting
3. Test with various article counts

## ğŸ” Security

- API keys stored in environment variables
- Database file excluded from version control
- Docker secrets management
- Rate limiting for external APIs
- Input validation and sanitization 